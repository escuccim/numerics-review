{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review-04-Eigenvalue-Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers to review questions from Chapter 4: Eigenvalue Problems <cite data-cite=\"heath2018scientific\">(Heath, 2018)</cite>.\n",
    "\n",
    "---\n",
    "Questions marked with $\\bigtriangledown$ are considered more difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.1. True or false: The eigenvalues of a matrix are not necessarily all distinct.\n",
    "\n",
    "True.  The eigenvalues are not distinct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.2. True or false: All the eigenvalues of a real matrix are necessarily real.\n",
    "\n",
    "False. The eigenvalues might be complex even when A is real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.3. True or false: An eigenvector corresponding to a given eigenvalue of a matrix is unique.\n",
    "\n",
    "False. Any multiple of an eigenvector is also an eigenvector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.4. True or false: Every n × n matrix A has n linearly independent eigenvectors.\n",
    "\n",
    "False. An $n \\times n$ matrix with fewer than $n$ linearly independent eigenvectors is defective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.5. True or false: If an n × n matrix is singu- lar, then it does not have a full set of n linearly independent eigenvectors.\n",
    "\n",
    "False.\n",
    "\n",
    "An $n \\times n$ matrix A is **diagonalizable** if A has n linearly independent eigenvectors.\n",
    "\n",
    "An $n \\times n$ matrix A is **singular** if there are fewer than n linearly independent columns.\n",
    "\n",
    "Linear indepdendence of eigenvectors and columns of $A$ are not related.  There exists singular matrices which are diagonizable and not diagonizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.6. True or false: A square matrix A is singular if, and only if, 0 is one of its eigenvalues.\n",
    "\n",
    "True.  The determinant of a matrix is the product of the eigenvalues\n",
    "$$\n",
    "|A| = \\lambda_1 \\lambda_2 \\cdots \\lambda_n\n",
    "$$\n",
    "\n",
    "A matrix with a determinant of 0 is singular.  Thus at least one of the eigenvalues must be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.7. True or false: If $\\lambda = 0$ for every eigenvalue $\\lambda$ of a matrix A, then A = O.\n",
    "\n",
    "True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.8. True or false: The diagonal elements of a complex Hermitian matrix must be real.\n",
    "\n",
    "True.  Since $A = A^H$, the diagonal elements must be their own complex conjugate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.9. True or false: The eigenvalues of a complex Hermitian matrix must be real.\n",
    "\n",
    "True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.10. True or false: If two matrices have the same eigenvalues, then the two matrices are similar.\n",
    "\n",
    "True. \n",
    "\n",
    "Two matrices are similar if $B = T^{-1} A T$.\n",
    "* $B$ and $A$ share the same **eigenvalues**.\n",
    "* If $y$ is an **eigenvector** of $B$ then $x$ is an eigenvector of $A$ such that $x = Ty$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.11. True or false: If two matrices are similar, then they have the same eigenvectors.\n",
    "\n",
    "False.\n",
    "\n",
    "Two matrices are similar if $B = T^{-1} A T$.\n",
    "* $B$ and $A$ share the same **eigenvalues**.\n",
    "* If $y$ is an **eigenvector** of $B$ then $x$ is an eigenvector of $A$ such that $x = Ty$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.12. True or false: Given any arbitrary square matrix, there is some diagonal matrix that is sim- ilar to it.\n",
    "\n",
    "False.  If $A$ has fewer than $n$ linearly independent eigenvectors, then it is not **diagonalizable** since the matrix $X$ in $X^{-1} A X = D$ is formed from the eigenvectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.17. True or false: If an $n \\times n$ matrix A has dis- tinct eigenvalues, then QR iteration applied to A necessarily converges to a diagonal matrix.\n",
    "\n",
    "False.  The matrix $A$ will converge to triagular form (not diagonal) where the diagonals are equal to the eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.19. Explain the distinction between a right eigenvector and a left eigenvector.\n",
    "\n",
    "In the equation below, the eigenvector $x$ is a right eigenvector because it appears to the right of $A$.\n",
    "$$\n",
    "A x = \\lambda x\n",
    "$$\n",
    "\n",
    "In contrast, the eigenvector $y^T$ is a left eigenvector because it appears to the left of $A$.\n",
    "$$\n",
    "y^T A = \\lambda y^T\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.21. For a given matrix A,\n",
    "(a) Can the same eigenvalue correspond to two\n",
    "different eigenvectors?\n",
    "(b) Can the same eigenvector correspond to two different eigenvalues?\n",
    "\n",
    "(a) Yes. For example the zero matrix has 3 unique eigenvectors but each eigenvector has the same eigenvalue (0).\n",
    "\n",
    "(b) No.  If $A x = \\lambda x$, there can only be a single value of $\\lambda$ for a unique value of $x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.25. What are the eigenvalues and eigenvectors of a diagonal matrix? Give an example.\n",
    "\n",
    "The eigenvalues of a diagonal matrix are the elements along the diagonal.\n",
    "\n",
    "The eigenvectors of a diagonal matrix form the identity matrix $I$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.27. Which of the following classes of matrices necessarily have all real eigenvalues?\n",
    "(a) Real symmetric\n",
    "(b) Real triangular\n",
    "(c) Arbitrary real\n",
    "(d) Complex symmetric\n",
    "(e) Complex Hermitian\n",
    "\n",
    "(a) True. A real symmetric matrix has real eigenvalues since eigenvalues are equal to the diagonal elements.\n",
    "\n",
    "(b) True. A real triangular matrix has real eigenvalues since eigenvalues are equal to diagonal elements.\n",
    "\n",
    "(c) False. An arbitrary matrix can have complex eigenvalues even if elements are real.\n",
    "\n",
    "(d) True. A complex symmetric matrix has real eigenvalues.\n",
    "\n",
    "(e) True. A complex Hermitian matrix has real eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.29. Give an example of a matrix that is not diagonalizable, i.e., that is not similar to any di- agonal matrix.\n",
    "\n",
    "A defective matrix that has fewer than $n$ linearly indepdendent eigenvectors is **not** diagonalizable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.31. Before applying QR iteration to compute the eigenvalues of a matrix, the matrix is usually first transformed to a simpler form. For each type of matrix listed below, what intermediate form is appropriate?\n",
    "\n",
    "(a) A general real matrix\n",
    "\n",
    "Transform $A$ to Hessenberg form using Householder transformation.\n",
    "* Like a triangular matrix, except either first superdiagonal or first subdiagonal are also nonzero.\n",
    "\n",
    "(b) A real symmetric matrix\n",
    "\n",
    "Transform $A$ to tridiagonal form.\n",
    "* Elements above the first superdiagonal and below the first subdiagonal are 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.33. Gauss-Jordan elimination reduces a matrix to diagonal form. Does this make the eigenvalues of the matrix obvious? Why?\n",
    "\n",
    "No.  The elementary row operations used by Gauss-Jordan elimination do not preserve eigenvalues.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.35. For which of the following classes of matri- ces of order n can the eigenvalues be computed in a finite number of steps for arbitrary n?\n",
    "\n",
    "(a) Diagonal\n",
    "\n",
    "Finite. Eigenvalues are elements along the diagonal.\n",
    "\n",
    "(b) Tridiagonal\n",
    "\n",
    "Use QR iteration which requires $O(10n^3)$.\n",
    "\n",
    "(c) Triangular\n",
    "\n",
    "Finite. Eigenvalues are elements along the diagonal.\n",
    "\n",
    "(d) Hessenberg\n",
    "\n",
    "Use QR iteration which requires $O(10n^3)$.\n",
    "\n",
    "(e) General real matrix with distinct eigenvalues\n",
    "\n",
    "Use QR iteration which requires $O(10n^3)$.\n",
    "\n",
    "(f) General real matrix with eigenvalues that are not necessarily distinct\n",
    "\n",
    "Use QR iteration which requires $O(10n^3)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.37. Applied to a given matrix A, QR iteration for computing eigenvalues converges to either di- agonal or triangular form. What property of A determines which of these two forms is obtained?\n",
    "\n",
    "For the general case, QR iteration converges to a **triangular** matrix with the eigenvalues given by the elements along the diagonal, but if a matrix is real symmetric or complex Hermitian then QR iteration converges to **diagonal** matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.39. If you had a routine for computing all the eigenvalues of a nonsymmetric matrix, how could you use it to compute the roots of any polynomial?\n",
    "\n",
    "Form the companion matrix from the monic form of the polynomial.  The eigenvalues of the companion matrix are the roots of the polynomial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.41. Power iteration converges to which eigen-\n",
    "vector of a matrix?\n",
    "\n",
    "Power iteration converges to the eigenvector that corresponds to the **maximum** absolute value eigenvalue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.43. Given an approximate eigenvector x for a matrix A, what is the best estimate (in the least squares sense) for the corresponding eigenvalue?\n",
    "\n",
    "The Rayleigh Quotient is the best estimate for the eigenvalue.\n",
    "$$\n",
    "x \\lambda = A x \\\\\n",
    "x^T x \\lambda = x^T A x \\\\\n",
    "\\lambda = \\frac{x^T A x}{x^T x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.45. Inverse iteration converges to which eigen- vector of a matrix?\n",
    "\n",
    "Inverse iteration converges to the eigenvector that corresponds to the **minimum** absolute value eigenvalue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.47. What is the main reason that shifts are used in iterative methods for computing eigenval- ues, such as the power, inverse iteration, and QR iteration methods?\n",
    "\n",
    "The primary use case for shifts is to accelerate convergence.  For methods which do not find the maximum or minimum eigenvalues such as power or inverse iteration, the shift can be used to find additional eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 4.57. (a) How are the singular values of an $m \\times n$ real matrix $A$ related to the eigenvalues of the $n \\times n$ matrix $A^T A$?\n",
    "(b) Is forming $A^T A$? and computing its eigenval- ues a good way to compute the singular values of a matrix $A$? Why?\n",
    "\n",
    "(a) The singular values of $A$ are the nonnegative square roots of the eigenvalues of $A^T A$.\n",
    "\n",
    "(b) Computing $A^T A$ introduces roundooff and as a result this is not a good way to compute the singular values of a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
