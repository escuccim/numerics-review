{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review-05-Nonlinear-Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers to review questions from Chapter 5: Nonlinear Equations <cite data-cite=\"heath2018scientific\">(Heath, 2018)</cite>.\n",
    "\n",
    "---\n",
    "Questions marked with $\\bigtriangledown$ are considered more difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.1. True or false: A small residual ∥f (x)∥ guar- antees an accurate solution of a system of nonlin- ear equations f(x) = 0.\n",
    "\n",
    "False. A small residual for an ill-conditioned system may not be accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.2. True or false: Newton’s method is an exam- ple of a fixed-point iteration scheme.\n",
    "\n",
    "\n",
    "True. Newton's method uses a fixed point scheme.\n",
    "\n",
    "One-dimension.\n",
    "$$\n",
    "x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}\n",
    "$$\n",
    "\n",
    "N-dimension.\n",
    "$$\n",
    "x_{k+1} = x_k - J(x_k)^{-1} f(x_k)  \n",
    "$$\n",
    "where\n",
    "\n",
    "* $J(x_k)$ is the Jacobian matrix of $f$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.3. True or false: If an iterative method for solving a nonlinear equation gains more than one bit of accuracy per iteration, then it is said to have a superlinear convergence rate.\n",
    "\n",
    "False. Superlinear convergence $1 < r < 2$ implies increasing (not constant) digits of precision per iteration eg $10^{-2}, 10^{-3}, 10^{-5}, 10^{-8}, 10^{-12}, \\cdots$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.4. True or false: For a given fixed level of accu- racy, a superlinearly convergent iterative method always requires fewer iterations than a linearly convergent method to find a solution to that level of accuracy.\n",
    "\n",
    "True.  As rate of convergence $r$ increases, then the number of iterations required to achieve a given level of accuracy decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.5. Suppose you are using an iterative method to solve a nonlinear equation f(x) = 0 for a root that is ill-conditioned, and you need to choose a convergence test. Would it be better to termi- nate the iteration when you find an iterate $x_k$ for which $|f (x_k )|$ is small, or when $|x_k − x_{k−1} |$ is small? Why?\n",
    "\n",
    "In general, residual $|f (xk )|$ is sensitive to the conditioning of the problem. As a result, for an ill-conditioned root using absolute difference between successive iterates $|x_k − x_{k−1} |$ is a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.6. (a) What is meant by a bracket for a non- linear function in one dimension?\n",
    "(b) What does this concept have to do with zero finding?\n",
    "\n",
    "(a) A bracket defines the interval $[a, b]$ of the values for $x_k$ used to evaluate the function $f$.\n",
    "\n",
    "(b) The bracket limits the values of $x_k$ used by an algorithm to some region over which the function $f$ is well behaved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.7. For root finding problems, why must we use an absolute rather than a relative condition num- ber in assessing sensitivity?\n",
    "\n",
    "Absolute condition number is required since the function value at the solution is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.8. (a) What is the definition of the conver- gence rate r of an iterative method?\n",
    "(b) Is it possible to have a cubically convergent method (r = 3) for finding a zero of a function?\n",
    "(c) If not, why, and if so, how might such a scheme be derived?\n",
    "\n",
    "(a) The convergence rate is the ratio of the errors between successive iterates.\n",
    "$$\n",
    "\\lim_{k \\rightarrow \\infty} \\frac{||e_{k+1}||}{||e_k||^2}\n",
    "$$\n",
    "\n",
    "(b) Yes.\n",
    "\n",
    "(c) Not sure. Higher order derivatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.9. If the errors at successive iterations of an iterative method are as follows, how would you characterize the convergence rate?\n",
    "\n",
    "(a) $10^{-2}, 10^{-4}, 10^{-8}, 10^{-16}, \\cdots$\n",
    "Quadratic convergence ($r = 2$).\n",
    "\n",
    "(b) $10^{-2}, 10^{-4}, 10^{-6}, 10^{-8}, \\cdots$\n",
    "Linear convergence ($r = 1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.10. What condition ensures that the bisection method will find a zero of a continuous nonlinear function f in the interval $[a, b]$?\n",
    "\n",
    "Intermediate Value Theorem: If $f$ is continuous on $[a, b]$ and sign($f(a)$) != sign($f(b)$), then there exists some point $x_k$ on $[a, b]$ where $f(x) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.11. (a) If the bisection method for finding a zero of a function f : R → R starts with an ini- tial bracket of length 1, what is the length of the interval containing the root after six iterations? (b) Do you need to know the particular function f to answer the question in part a?\n",
    "(c) If we assume that it is started with a bracket for the solution in which there is a sign change, is the convergence rate of the bisection method de- pendent on whether the solution sought is a simple root or a multiple root? Why?\n",
    "\n",
    "(a) Length of interval after $k$ iterations given by $0.5^{k}$ where $k = 6$.\n",
    "\n",
    "(b) No.\n",
    "\n",
    "(c) Convergence rate of bisection does not depend on whether there is a single or multiple root."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.13. What is meant by a quadratic convergence rate for an iterative method?\n",
    "\n",
    "Quadratic convergence $r = 2$ means increasing digits of precision per iteration eg $10^{-2}, 10^{-4}, 10^{-8}, 10^{-16}, \\cdots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.15. (a) What does it mean for a root of an equation to be a multiple root?\n",
    "(b) What is the effect of a multiple root on the convergence rate of the bisection method?\n",
    "(c) What is the effect of a multiple root on the convergence rate of Newton’s method?\n",
    "\n",
    "(a) A multiple root means that there is more than one value for $x_k$ such $f(x_k) = 0$.\n",
    "\n",
    "(b) Multiple root does not impact convergence rate of bisection method.\n",
    "\n",
    "(c) Multiple root reduces convergence rate of Newton's method to $C = 1 - (1/m)$ where $m$ is the number of roots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.17. What is the convergence rate for Newton’s method for finding the root $x = 2$ of each of the following equations?\n",
    "(a) $f(x) = (x−1)(x−2)^2 = 0$ (b) $f(x) = (x−1)^2(x−2) = 0$\n",
    "\n",
    "For multiple root, Newton's method has convergence rate of $C = 1 - (1/m)$ where $m$ is the number of roots.\n",
    "\n",
    "(a) $m = 2$ and $C = 1 - 1/2 = 0.5$\n",
    "\n",
    "(b) $m = 2$ and $C = 1 - 1/2 = 0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.19. In using the secant method for solving a one-dimensional nonlinear equation,\n",
    "(a) How many starting guesses for the solution are required?\n",
    "(b) How many new function evaluations are re- quired per iteration?\n",
    "\n",
    "(a) Secant method requires 1 initial guess for $x_0$.\n",
    "\n",
    "(b) Secant method requires 1 function evaluation per iteration (assuming that function evaluation from previous step is cached).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.21. In bracketing a zero of a nonlinear func- tion, one needs to determine if two function val- ues, say $f(a)$ and $f(b)$, differ in sign. Is the fol- lowing a good way to test for this condition: if (f(a) ∗ f(b) < 0)...? Why?\n",
    "\n",
    "Multiplying two numbers has the potential to overflow thus potentially changing the sign of the result in comparison to what is obtained with exact arithmetic.  A better solution is to normalize each quantity to $\\{-1, 0, 1\\}$ and multiply the normalized values which do not overflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.23. List one advantage and one disadvantage of the secant method compared with the bisection method for finding a simple zero of a single non- linear equation.\n",
    "\n",
    "Advantage\n",
    "- Secant method has faster convergence ($r \\approx 1.6$) in comparison to bisection ($r = 1$).\n",
    "\n",
    "Disadvantage\n",
    "- Secant method might not converge if initial guess $x_0$ is not close to solution whereas bisection is guaranteed to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.27. Rank the following methods 1 through 3, from slowest convergence rate to fastest conver- gence rate, for finding a simple root of a nonlinear equation in one dimension:\n",
    "(a) Bisection method (b) Newton’s method (c) Secant method\n",
    "\n",
    "Slowest-to-fastest convergence\n",
    "\n",
    "(a) Bisection method ($r = 1$)\n",
    "\n",
    "(c) Secant method ($r \\approx 1.6$)\n",
    "\n",
    "(b) Newton's method ($r = 2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.29. In solving a nonlinear equation $f(x) = 0$, if you assume that the cost of evaluating the deriva- tive $f′(x)$ is about the same as the cost of evalu- ating $f(x)$, how does the cost of Newton’s method compare with the cost of the secant method per iteration?\n",
    "\n",
    "In one dimension, Newton's method evaluates $f(x_k)$ and $f′(x_k)$.\n",
    "$$\n",
    "x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}\n",
    "$$\n",
    "\n",
    "The Secant method evaluates $f(x_k)$.\n",
    "$$\n",
    "x_{k+1} = x_k - f(x_k) \\frac{x_{k} - x_{k-1}}{f(x_k) - f(x_{k-1})}\n",
    "$$\n",
    "\n",
    "As a result, the cost-per-iteration of Newton's method is twice as large as the Secant method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.31. Suppose that you are using fixed-point it- eration based on the fixed-point problem $x = g(x)$ to find a solution $x∗$ to a nonlinear equation $f(x) = 0$. Which would be more favorable for the convergence rate: a horizontal tangent of $g$ at $x∗$ or a horizontal tangent of $f$ at $x∗$? Why?\n",
    "\n",
    "A horizontal tangent of $f$ at $x*$ implies slow convergence.\n",
    "\n",
    "A horizontal tangent of $g$ at $x*$ implies that $|g'(x)| < 1$ which implies that the solution converges.\n",
    "\n",
    "As a result, a horizontal tangent of $g$ at $x*$ is more favorable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.33. For what type of function is linear frac- tional interpolation a particularly good choice of zero finder?\n",
    "\n",
    "Linear fractional interpolation is a better choice than Newton's method or Secant method when the function whose root is sought have a horizontal or vertical asymptote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.35. State at least one method for finding all the zeros of a polynomial, and discuss its advantages and disadvantages.\n",
    "\n",
    "1. Use Newton's method or Secant method to find a single root $x_1$.\n",
    "2. Compute the **deflated polynomial** $p(x) = p(x) / (x - x_1)$.\n",
    "3. Repeat from step 1 using the deflated polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.37. For solving an n-dimensional nonlinear equation, how many scalar function evaluations are required per iteration of Newton’s method?\n",
    "\n",
    "Newton's method in n-dimensions uses only 1 function evaluation per-iteration, however the Jacobian must also be evaluated at $x_k$ and we must also solve the linear system $J(x_k)^{-1}$.  As a result, Newton's method in n-dimensions is quite costly.\n",
    "$$\n",
    "x_{k+1} = x_k - J(x_k)^{-1} f(x_k)  \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 5.39. Give two reasons why secant updating methods for solving systems of nonlinear equa- tions are often more efficient than Newton’s method despite converging more slowly.\n",
    "\n",
    "Secant updating methods (such as Broyden):\n",
    "1. Evaluate an approximate Jacobian rather than the true Jacobian.\n",
    "2. Factorize the approximate Jacobian to avoid repeated computation at each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
